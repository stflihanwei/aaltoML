{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**30E03000 - Data Science for Business I (2022)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First exam - 22.02.2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case: Healthcare analytics (60pt)\n",
    "\n",
    "Assume that you are consulting a hospital that aims at improving patient outcomes, efficiency and reducing costs. The data set that the hospital has provided to you contains profiles of several patients including their demographic details along with a set of medical measurements taken during their recent visit (M1 - M9). The objective is to predict which patients should be called for further clinical testing. The testing procedure is costly and the hospital would like to avoid calling healthy patients for an additional test.\n",
    "\n",
    "The data set is provided in the file **healthcare.csv**. Relevant background information on the variables is provided in the file **healthcare-variables.txt**.\n",
    "\n",
    "When completing the following steps, you should answer the quiz in MyCourses. Please remember, that you still need to submit the completed notebook. **Add markdown and code boxes as many as you need**.\n",
    "\n",
    "***\n",
    "\n",
    "***\n",
    "\n",
    "### Submission\n",
    "\n",
    "Answer the quiz and upload your filled-out notebook in **.ipynb format** in the exam submission box. Name your file studentNum-lastname-firstname-exam.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 (10pt):\n",
    "\n",
    "Load data set from \"healthcare.csv\" file. Perform exploratory data analysis to understand your data better. Check for missing (or otherwise weird) values and variable types. Transform variables when needed (e.g., dummies). You can also drop variables that you don't want to include, but justify your decision!\n",
    "\n",
    "To preprocess,\n",
    "1. If you find missing values, remove every row containing a missing value\n",
    "2. Drop the running identifier column\n",
    "3. Convert the target variable to integer type\n",
    "4. Perform one-hot encoding for the categorical variables (sex, education, employment, marital, abroad, trust, sport, smoke) using `get_dummies` from Pandas library\n",
    "\n",
    "Please note that any mistake in the preprocessing steps will potentially cost you a lot of points in the subsequent steps.\n",
    "\n",
    "Q 1.1 How many rows do you have after the elimination of missing values?\n",
    "* 1001\n",
    "* 1482\n",
    "* 1500\n",
    "* 1082\n",
    "* 1020\n",
    "* none of the mentioned\n",
    "\n",
    "Q 1.2 How many columns do you have right after dropping the identifier column and before one-hot encoding?\n",
    "* 24\n",
    "* 25\n",
    "* 1500\n",
    "* 23\n",
    "* none of the mentioned\n",
    "\n",
    "Q 1.3 How many columns do you have right after performing one-hot encoding?\n",
    "* 40\n",
    "* 46\n",
    "* 51\n",
    "* 24\n",
    "* 25\n",
    "* none of the mentioned\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Task 2 (5pt):\n",
    "\n",
    "Split the data into training (70%) and testing (30%) data sets. Check outcome distributions on training and test datasets. Use `train_test_split` from `sklearn.model_selection`. Set the seed with `random_state=12345` when performing the split.\n",
    "\n",
    "What is the proportion of the class \"no need\" in the training set? Choose the closest value.\n",
    "* 79%\n",
    "* 21%\n",
    "* 78%\n",
    "* 22%\n",
    "* 50%\n",
    "\n",
    "What is the proportion of the class \"no need\" in the test set? Choose the closest value.\n",
    "* 79%\n",
    "* 21%\n",
    "* 78%\n",
    "* 22%\n",
    "* 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Task 3 (15pt):\n",
    "\n",
    "Train a simple decision tree model using `DecisionTreeClassifier` from `sklearn.tree` with the following parameters: `criterion=\"gini\", random_state=100, max_depth=3, min_samples_leaf=3`.\n",
    "\n",
    "Use the classifier to predict labels and probabilities for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the performance of the model. How does it perform on the test set? (5pt)\n",
    "\n",
    "Q 3.1 What is the accuracy of the decision tree model? Choose the interval that contains the value.\n",
    "* [50%, 55%]\n",
    "* [55%, 60%]\n",
    "* [60%, 65%]\n",
    "* [65%, 70%]\n",
    "* [70%, 75%]\n",
    "* [75%, 80%]\n",
    "\n",
    "Q 3.2 What is the AUC score? Choose the interval that contains the value.\n",
    "* [0.50, 0.55]\n",
    "* [0.55, 0.60]\n",
    "* [0.60, 0.65]\n",
    "* [0.65, 0.70]\n",
    "* [0.70, 0.75]\n",
    "* [0.75, 0.80]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which variables appear to be most important for predicting the success of a campaign? (5pt)\n",
    "\n",
    "Q 3.3 Choose the top-3 features based on the importance of the variable.\n",
    "* bmi\n",
    "* sport_NO\n",
    "* employment_LONG-TERM SICK/DISABLED\n",
    "* marital_MARRIED\n",
    "* income\n",
    "* smoke_YES\n",
    "* m1\n",
    "* depress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpret the decision tree produced by the model. What insights can you get from it? (5pt)\n",
    "\n",
    "Q 3.4 Interpret the generated decision tree. Which of the following claims are true?\n",
    "* Everyone with a low score for depress is classified as \"no need\".\n",
    "* If a person is married, there is no need for a test according to the model.\n",
    "* According to the model, an unmarried person with income below 1335 needs a test regardless of other variables.\n",
    "* It is possible that the model classifies a person with a low m6-value as \"no need\".\n",
    "\n",
    "Q 3.5 Does the following case need a test according to the model?\n",
    "* depress=5\n",
    "* married\n",
    "* m1 -0.5\n",
    "* m5 1.5\n",
    "* income 2100\n",
    "* m6 0.010\n",
    "* the person smokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Task 4 (10pt):\n",
    "\n",
    "Could the model be improved by using rebalancing techniques? To answer this, check how the model from Task 3 would perform on a balanced dataset. For balancing, use `RandomUnderSampler` from the package `imblearn.under_sampling`. Use the settings `random_state=1234` and `sampling_strategy='majority'` for `RandomUnderSampler`.\n",
    "\n",
    "Q 4.1 What is the accuracy of the decision tree model with balanced data? Choose the interval that contains the value.\n",
    "* [50%, 55%]\n",
    "* [55%, 60%]\n",
    "* [60%, 65%]\n",
    "* [65%, 70%]\n",
    "* [70%, 75%]\n",
    "* [75%, 80%]\n",
    "\n",
    "Q 4.2 What is the AUC score of the decision tree model with balanced data? Choose the interval that contains the value.\n",
    "* [0.50, 0.55]\n",
    "* [0.55, 0.60]\n",
    "* [0.60, 0.65]\n",
    "* [0.65, 0.70]\n",
    "* [0.70, 0.75]\n",
    "* [0.75, 0.80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Task 5 (25pt):\n",
    "\n",
    "Use the data to train additional competing classification models (in addition to the decision tree models from Task 3 and 4). Use logistic regression with settings `LogisticRegression(solver='liblinear', max_iter=10000, penalty='l1', C=0.05, random_state=1234)`. Fit a model with the unbalanced training data and another with the balanced data.\n",
    "\n",
    "Plot the ROC curves for all the models you have fitted thus far (4 models: two decision trees and two logistic regression models).\n",
    "\n",
    "Q 5.1 Look at the the ROC curves. Which of the models has the highest true positive rate when the false positive rate is 0.6?\n",
    "* Decision tree, unbalanced\n",
    "* Decision tree, balanced\n",
    "* Logistic regression, unbalanced\n",
    "* Logistic regression, balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppose that the cost of a single test is 500, and the reward (or costs saved) due to a successfully detected case is 13000. (10pt)\n",
    "\n",
    "Q 5.2 What is the expected benefit per patient for the unbalanced decision tree model (the model from Task 3)? Choose the interval that contains the value.\n",
    "* 0-10\n",
    "* 10-100\n",
    "* 100-1000\n",
    "* 1000-2000\n",
    "* 2000-10000\n",
    "\n",
    "Q 5.3 Which of the four models has the highest expected benefit?\n",
    "* Decision tree, unbalanced\n",
    "* Decision tree, balanced\n",
    "* Logistic regression, unbalanced\n",
    "* Logistic regression, balanced\n",
    "\n",
    "Q 5.4 Which of the four models has the lowest expected benefit?\n",
    "* Decision tree, unbalanced\n",
    "* Decision tree, balanced\n",
    "* Logistic regression, unbalanced\n",
    "* Logistic regression, balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "nteract": {
   "version": "0.21.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
